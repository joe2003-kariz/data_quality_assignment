{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e31e199",
   "metadata": {},
   "source": [
    "# Data Wrangling Operations Notebook\n",
    "This notebook performs the full wrangling pipeline described in **Section 5** of the assignment. Created on 2025-07-26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203323cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data sample:\n",
      "  Currency      Rate        Date\n",
      "0      USD    1.0932  2025-07-25\n",
      "1      GBP    0.8456  2025-07-25\n",
      "2      JPY  141.2100  2025-07-25\n",
      "3      CHF    0.9678  2025-07-25\n",
      "4      CAD    1.4783  2025-07-25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-downloaded ECB exchange rate dataset\n",
    "ecb_df = pd.read_csv('ecb_exchange_rates (1).csv')\n",
    "\n",
    "# Inspect initial data\n",
    "print(\"Initial data sample:\")\n",
    "print(ecb_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85451be6",
   "metadata": {},
   "source": [
    "## Step 1: Handle Missing Values and Parse Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af3fec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Currency    0\n",
      "Rate        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Student\\AppData\\Local\\Temp\\ipykernel_9000\\4081459524.py:13: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  ecb_df_interpolated = ecb_df.interpolate()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert date column\n",
    "ecb_df['Date'] = pd.to_datetime(ecb_df['Date'])\n",
    "ecb_df.set_index('Date', inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(ecb_df.isnull().sum())\n",
    "\n",
    "# Forward fill to handle missing values\n",
    "ecb_df_filled = ecb_df.ffill()\n",
    "\n",
    "# Interpolation for smooth filling\n",
    "ecb_df_interpolated = ecb_df.interpolate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e2c367",
   "metadata": {},
   "source": [
    "## Step 2: Resample and Standardize Time Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "926a5fc9-78f9-4e86-87d7-d538b911a7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column data types:\n",
      "Rate    float64\n",
      "dtype: object\n",
      "\n",
      "Numeric columns detected:\n",
      "Index(['Rate'], dtype='object')\n",
      "\n",
      "Preview of numeric data after grouping and sorting:\n",
      "                Rate\n",
      "Date                \n",
      "2025-07-25  29.11898\n",
      "\n",
      "Resampled Data (first 5 rows):\n",
      "                Rate\n",
      "Date                \n",
      "2025-07-25  29.11898\n"
     ]
    }
   ],
   "source": [
    "# Step: Clean duplicate dates and prepare for resampling\n",
    "\n",
    "# Print column types\n",
    "print(\"Column data types:\")\n",
    "print(ecb_df_interpolated.dtypes)\n",
    "\n",
    "# Identify numeric columns only (exclude strings/objects)\n",
    "numeric_cols = ecb_df_interpolated.select_dtypes(include='number').columns\n",
    "print(\"\\nNumeric columns detected:\")\n",
    "print(numeric_cols)\n",
    "\n",
    "# If no numeric columns were found, print warning\n",
    "if numeric_cols.empty:\n",
    "    print(\"\\n⚠️ No numeric columns found. Check your dataset structure.\")\n",
    "else:\n",
    "    # Group by the date index and average only numeric columns\n",
    "    ecb_df_interpolated = ecb_df_interpolated[numeric_cols].groupby(ecb_df_interpolated.index).mean()\n",
    "\n",
    "    # Sort the index to ensure chronological order\n",
    "    ecb_df_interpolated = ecb_df_interpolated.sort_index()\n",
    "\n",
    "    # Show preview before resampling\n",
    "    print(\"\\nPreview of numeric data after grouping and sorting:\")\n",
    "    print(ecb_df_interpolated.head())\n",
    "\n",
    "    # Now resample to daily frequency\n",
    "    ecb_daily = ecb_df_interpolated.resample('D').ffill()\n",
    "\n",
    "    print(\"\\nResampled Data (first 5 rows):\")\n",
    "    print(ecb_daily.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab32813",
   "metadata": {},
   "source": [
    "## Step 3: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f403e110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and normalized data:\n",
      "                Rate  Norm_Rate  Norm_Norm_Rate  Norm_Norm_Norm_Rate\n",
      "Date                                                                \n",
      "2025-07-25  29.11898        0.0             0.0                  0.0\n"
     ]
    }
   ],
   "source": [
    "# Min‑max normalization for all numeric columns in ecb_daily, handling constant-series edge case\n",
    "numeric_cols = ecb_daily.select_dtypes(include='number').columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    col_min = ecb_daily[col].min()\n",
    "    col_max = ecb_daily[col].max()\n",
    "    if col_max == col_min:\n",
    "        # All values identical—set normalized to 0\n",
    "        ecb_daily[f'Norm_{col}'] = 0.0\n",
    "    else:\n",
    "        # Standard min-max normalization\n",
    "        ecb_daily[f'Norm_{col}'] = (\n",
    "            ecb_daily[col] - col_min\n",
    "        ) / (\n",
    "            col_max - col_min\n",
    "        )\n",
    "\n",
    "# Drop only rows where *all* numeric and normalized columns are NaN\n",
    "ecb_cleaned = ecb_daily.dropna(how='all')\n",
    "\n",
    "# Preview processed and normalized data\n",
    "print(\"Processed and normalized data:\")\n",
    "print(ecb_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532bdfc",
   "metadata": {},
   "source": [
    "## Step 4: Save Final Wrangled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64fd060e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved as 'ecb_cleaned_final.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save to new CSV\n",
    "ecb_cleaned.to_csv(\"ecb_cleaned_final.csv\")\n",
    "\n",
    "# Confirm\n",
    "print(\"Saved as 'ecb_cleaned_final.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f02da9-6628-4b01-8f6a-0666002e504d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
